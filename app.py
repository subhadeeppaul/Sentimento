{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# EDA Pkgs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tweepy\n",
    "import json\n",
    "from tweepy import OAuthHandler\n",
    "import re\n",
    "import textblob\n",
    "from textblob import TextBlob\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import openpyxl\n",
    "import time\n",
    "import tqdm\n",
    "\n",
    "#To Hide Warnings\n",
    "st.set_option('deprecation.showfileUploaderEncoding', False)\n",
    "st.set_option('deprecation.showPyplotGlobalUse', False)\n",
    "# Viz Pkgs\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import seaborn as sns\n",
    "#sns.set_style('darkgrid')\n",
    "\n",
    "\n",
    "STYLE = \"\"\"\n",
    "<style>\n",
    "img {\n",
    "    max-width: 100%;\n",
    "}\n",
    "</style> \"\"\"\n",
    "\n",
    "def main():\n",
    "    \"\"\" Common ML Dataset Explorer \"\"\"\n",
    "    #st.title(\"Live twitter Sentiment analysis\")\n",
    "    #st.subheader(\"Select a topic which you'd like to get the sentiment analysis on :\")\n",
    "\n",
    "    html_temp = \"\"\"\n",
    "\t<div style=\"background-color:tomato;\"><p style=\"color:white;font-size:40px;padding:9px\">Live twitter Sentiment analysis</p></div>\n",
    "\t\"\"\"\n",
    "    st.markdown(html_temp, unsafe_allow_html=True)\n",
    "    st.subheader(\"Select a topic which you'd like to get the sentiment analysis on :\")\n",
    "\n",
    "    ################# Twitter API Connection #######################\n",
    "    consumer_key = \"Enter Key Here\"\n",
    "    consumer_secret = \"Enter Key Here\"\n",
    "    access_token = \"Enter Key Here\"\n",
    "    access_token_secret = \"Enter Key Here\"\n",
    "\n",
    "\n",
    "\n",
    "    # Use the above credentials to authenticate the API.\n",
    "\n",
    "    auth = tweepy.OAuthHandler( consumer_key , consumer_secret )\n",
    "    auth.set_access_token( access_token , access_token_secret )\n",
    "    api = tweepy.API(auth)\n",
    "    ################################################################\n",
    "    \n",
    "    df = pd.DataFrame(columns=[\"Date\",\"User\",\"IsVerified\",\"Tweet\",\"Likes\",\"RT\",'User_location'])\n",
    "    \n",
    "    # Write a Function to extract tweets:\n",
    "    def get_tweets(Topic,Count):\n",
    "        i=0\n",
    "        #my_bar = st.progress(100) # To track progress of Extracted tweets\n",
    "        for tweet in tweepy.Cursor(api.search, q=Topic,count=100, lang=\"en\",exclude='retweets').items():\n",
    "            #time.sleep(0.1)\n",
    "            #my_bar.progress(i)\n",
    "            df.loc[i,\"Date\"] = tweet.created_at\n",
    "            df.loc[i,\"User\"] = tweet.user.name\n",
    "            df.loc[i,\"IsVerified\"] = tweet.user.verified\n",
    "            df.loc[i,\"Tweet\"] = tweet.text\n",
    "            df.loc[i,\"Likes\"] = tweet.favorite_count\n",
    "            df.loc[i,\"RT\"] = tweet.retweet_count\n",
    "            df.loc[i,\"User_location\"] = tweet.user.location\n",
    "            #df.to_csv(\"TweetDataset.csv\",index=False)\n",
    "            #df.to_excel('{}.xlsx'.format(\"TweetDataset\"),index=False)   ## Save as Excel\n",
    "            i=i+1\n",
    "            if i>Count:\n",
    "                break\n",
    "            else:\n",
    "                pass\n",
    "    # Function to Clean the Tweet.\n",
    "    def clean_tweet(tweet):\n",
    "        return ' '.join(re.sub('(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|([RT])', ' ', tweet.lower()).split())\n",
    "    \n",
    "        \n",
    "    # Funciton to analyze Sentiment\n",
    "    def analyze_sentiment(tweet):\n",
    "        analysis = TextBlob(tweet)\n",
    "        if analysis.sentiment.polarity > 0:\n",
    "            return 'Positive'\n",
    "        elif analysis.sentiment.polarity == 0:\n",
    "            return 'Neutral'\n",
    "        else:\n",
    "            return 'Negative'\n",
    "    \n",
    "    #Function to Pre-process data for Worlcloud\n",
    "    def prepCloud(Topic_text,Topic):\n",
    "        Topic = str(Topic).lower()\n",
    "        Topic=' '.join(re.sub('([^0-9A-Za-z \\t])', ' ', Topic).split())\n",
    "        Topic = re.split(\"\\s+\",str(Topic))\n",
    "        stopwords = set(STOPWORDS)\n",
    "        stopwords.update(Topic) ### Add our topic in Stopwords, so it doesnt appear in wordClous\n",
    "        ###\n",
    "        text_new = \" \".join([txt for txt in Topic_text.split() if txt not in stopwords])\n",
    "        return text_new\n",
    "\n",
    "    \n",
    "    #\n",
    "    from PIL import Image\n",
    "    image = Image.open('Logo1.jpg')\n",
    "    st.image(image, caption='Twitter for Analytics',use_column_width=True)\n",
    "    \n",
    "    \n",
    "    # Collect Input from user :\n",
    "    Topic = str()\n",
    "    Topic = str(st.text_input(\"Enter the topic you are interested in (Press Enter once done)\"))     \n",
    "    \n",
    "    if len(Topic) > 0 :\n",
    "        \n",
    "        # Call the function to extract the data. pass the topic and filename you want the data to be stored in.\n",
    "        with st.spinner(\"Please wait, Tweets are being extracted\"):\n",
    "            get_tweets(Topic , Count=200)\n",
    "        st.success('Tweets have been Extracted !!!!')    \n",
    "           \n",
    "    \n",
    "        # Call function to get Clean tweets\n",
    "        df['clean_tweet'] = df['Tweet'].apply(lambda x : clean_tweet(x))\n",
    "    \n",
    "        # Call function to get the Sentiments\n",
    "        df[\"Sentiment\"] = df[\"Tweet\"].apply(lambda x : analyze_sentiment(x))\n",
    "        \n",
    "        \n",
    "        # Write Summary of the Tweets\n",
    "        st.write(\"Total Tweets Extracted for Topic '{}' are : {}\".format(Topic,len(df.Tweet)))\n",
    "        st.write(\"Total Positive Tweets are : {}\".format(len(df[df[\"Sentiment\"]==\"Positive\"])))\n",
    "        st.write(\"Total Negative Tweets are : {}\".format(len(df[df[\"Sentiment\"]==\"Negative\"])))\n",
    "        st.write(\"Total Neutral Tweets are : {}\".format(len(df[df[\"Sentiment\"]==\"Neutral\"])))\n",
    "        \n",
    "        # See the Extracted Data : \n",
    "        if st.button(\"See the Extracted Data\"):\n",
    "            #st.markdown(html_temp, unsafe_allow_html=True)\n",
    "            st.success(\"Below is the Extracted Data :\")\n",
    "            st.write(df.head(50))\n",
    "        \n",
    "        \n",
    "        # get the countPlot\n",
    "        if st.button(\"Get Count Plot for Different Sentiments\"):\n",
    "            st.success(\"Generating A Count Plot\")\n",
    "            st.subheader(\" Count Plot for Different Sentiments\")\n",
    "            st.write(sns.countplot(df[\"Sentiment\"]))\n",
    "            st.pyplot()\n",
    "        \n",
    "        # Piechart \n",
    "        if st.button(\"Get Pie Chart for Different Sentiments\"):\n",
    "            st.success(\"Generating A Pie Chart\")\n",
    "            a=len(df[df[\"Sentiment\"]==\"Positive\"])\n",
    "            b=len(df[df[\"Sentiment\"]==\"Negative\"])\n",
    "            c=len(df[df[\"Sentiment\"]==\"Neutral\"])\n",
    "            d=np.array([a,b,c])\n",
    "            explode = (0.1, 0.0, 0.1)\n",
    "            st.write(plt.pie(d,shadow=True,explode=explode,labels=[\"Positive\",\"Negative\",\"Neutral\"],autopct='%1.2f%%'))\n",
    "            st.pyplot()\n",
    "            \n",
    "            \n",
    "        # get the countPlot Based on Verified and unverified Users\n",
    "        if st.button(\"Get Count Plot Based on Verified and unverified Users\"):\n",
    "            st.success(\"Generating A Count Plot (Verified and unverified Users)\")\n",
    "            st.subheader(\" Count Plot for Different Sentiments for Verified and unverified Users\")\n",
    "            st.write(sns.countplot(df[\"Sentiment\"],hue=df.IsVerified))\n",
    "            st.pyplot()\n",
    "        \n",
    "        \n",
    "        ## Points to add 1. Make Backgroud Clear for Wordcloud 2. Remove keywords from Wordcloud\n",
    "        \n",
    "        \n",
    "        # Create a Worlcloud\n",
    "        if st.button(\"Get WordCloud for all things said about {}\".format(Topic)):\n",
    "            st.success(\"Generating A WordCloud for all things said about {}\".format(Topic))\n",
    "            text = \" \".join(review for review in df.clean_tweet)\n",
    "            stopwords = set(STOPWORDS)\n",
    "            text_newALL = prepCloud(text,Topic)\n",
    "            wordcloud = WordCloud(stopwords=stopwords,max_words=800,max_font_size=70).generate(text_newALL)\n",
    "            st.write(plt.imshow(wordcloud, interpolation='bilinear'))\n",
    "            st.pyplot()\n",
    "        \n",
    "        \n",
    "        #Wordcloud for Positive tweets only\n",
    "        if st.button(\"Get WordCloud for all Positive Tweets about {}\".format(Topic)):\n",
    "            st.success(\"Generating A WordCloud for all Positive Tweets about {}\".format(Topic))\n",
    "            text_positive = \" \".join(review for review in df[df[\"Sentiment\"]==\"Positive\"].clean_tweet)\n",
    "            stopwords = set(STOPWORDS)\n",
    "            text_new_positive = prepCloud(text_positive,Topic)\n",
    "            #text_positive=\" \".join([word for word in text_positive.split() if word not in stopwords])\n",
    "            wordcloud = WordCloud(stopwords=stopwords,max_words=800,max_font_size=70).generate(text_new_positive)\n",
    "            st.write(plt.imshow(wordcloud, interpolation='bilinear'))\n",
    "            st.pyplot()\n",
    "        \n",
    "        \n",
    "        #Wordcloud for Negative tweets only       \n",
    "        if st.button(\"Get WordCloud for all Negative Tweets about {}\".format(Topic)):\n",
    "            st.success(\"Generating A WordCloud for all Positive Tweets about {}\".format(Topic))\n",
    "            text_negative = \" \".join(review for review in df[df[\"Sentiment\"]==\"Negative\"].clean_tweet)\n",
    "            stopwords = set(STOPWORDS)\n",
    "            text_new_negative = prepCloud(text_negative,Topic)\n",
    "            #text_negative=\" \".join([word for word in text_negative.split() if word not in stopwords])\n",
    "            wordcloud = WordCloud(stopwords=stopwords,max_words=800,max_font_size=70).generate(text_new_negative)\n",
    "            st.write(plt.imshow(wordcloud, interpolation='bilinear'))\n",
    "            st.pyplot()\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    st.sidebar.header(\"About App\")\n",
    "    st.sidebar.info(\"A Twitter Sentiment analysis Project which will scrap twitter for the topic selected by the user. The extracted tweets will then be used to determine the Sentiments of those tweets. \\\n",
    "                    The different Visualizations will help us get a feel of the overall mood of the people on Twitter regarding the topic we select.\")\n",
    "    st.sidebar.text(\"Built with Streamlit\")\n",
    "    \n",
    "    st.sidebar.header(\"For Any Queries/Suggestions Please reach out at :\")\n",
    "    st.sidebar.info(\"subhadeeppaul35@gmail.com\")\n",
    "    #st.sidebar.subheader(\"Scatter-plot setup\")\n",
    "    #box1 = st.sidebar.selectbox(label= \"X axis\", options = numeric_columns)\n",
    "    #box2 = st.sidebar.selectbox(label=\"Y axis\", options=numeric_columns)\n",
    "    #sns.jointplot(x=box1, y= box2, data=df, kind = \"reg\", color= \"red\")\n",
    "    #st.pyplot()\n",
    "\n",
    "\n",
    "\n",
    "    if st.button(\"Exit\"):\n",
    "        st.balloons()\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
